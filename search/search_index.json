{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Computa\u00e7\u00e3o em Nuvem","text":"Edi\u00e7\u00e3o <p>2024.2: roteiros </p> <p>2025.1: projeto</p>"},{"location":"#kit-u","title":"KIT-U","text":"<ul> <li>Giovana Cassoni Andrade</li> <li>Lucas Hix</li> </ul>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 26/03/2025</li> <li> Roteiro 2 - Data 26/03/2025</li> <li> Roteiro 3 - Data 28/05/2025</li> <li> Roteiro 4 - Data 28/05/2025</li> <li> Projeto - Data 28/05/2025</li> </ul>"},{"location":"#textos-e-imagens-dos-roteiros","title":"Textos e imagens dos roteiros","text":"<p>Para ver os roteiros originais em PDF, eles est\u00e3o presentes em suas respectivas abas de roteiro.</p> <p>Para obter os textos, legendas e imagens dos roteiros para coloc\u00e1-los nas p\u00e1ginas, foram instaladas a biblioteca poppler e a ferramenta pdfminer.six com:</p> <pre><code>brew install poppler\npip install pdfminer.six\n</code></pre> <p>E, para cada um dos roteiros, foram utilizados os comandos a seguir:</p> <pre><code>pdfimages -png Roteiro_X_de_Cloud.pdf imgs/roteiroX\npdf2txt.py Roteiro_X_de_Cloud.pdf &gt; Roteiro_X_de_Cloud.md\n</code></pre>"},{"location":"projeto/documentacao/","title":"Documenta\u00e7\u00e3o","text":""},{"location":"projeto/documentacao/#projeto","title":"Projeto","text":"<p>Link do Reposit\u00f3rio: https://github.com/Peng1104/Projeto-Cloud</p> <p>Este projeto \u00e9 uma API FastAPI para manipula\u00e7\u00e3o de usu\u00e1rios e consulta de dados do jogo Grepolis.</p>"},{"location":"projeto/documentacao/#etapa-1","title":"ETAPA 1","text":""},{"location":"projeto/documentacao/#o-que-foi-feito","title":"O que foi feito?","text":"<p>Foram feitos os endopoints, modelos e configura\u00e7\u00f5es necess\u00e1rias para criar uma aplica\u00e7\u00e3o que permite o cadastro e autentica\u00e7\u00e3o de usu\u00e1rios, al\u00e9m da consulta de dados dos jogadores do jogo Grepolis.</p> <p>Os dados obtidos atrav\u00e9s de endpoints espec\u00edficos do Grepolis s\u00e3o combinados em um DataFrame para facilitar a manipula\u00e7\u00e3o e exibi\u00e7\u00e3o, atualizados de hora em hora.</p> <p>O projeto possui a seguinte estrutura de pastas e arquivos:</p> Estrutura<pre><code>\ud83d\udcc1 app/\n\u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u251c\u2500\u2500 \ud83d\udcc4 requirements.txt\n\u251c\u2500\u2500 \ud83d\udcc4 .dockerignore\n\u2514\u2500\u2500 \ud83d\udcc1 web_app/\n    \u251c\u2500\u2500 \ud83d\udcc4 __main__.py\n    \u251c\u2500\u2500 \ud83d\udcc4 app_models.py\n    \u251c\u2500\u2500 \ud83d\udcc4 app_routes.py\n    \u251c\u2500\u2500 \ud83d\udcc4 db_manager.py\n    \u251c\u2500\u2500 \ud83d\udcc4 db_models.py\n    \u251c\u2500\u2500 \ud83d\udcc4 grepolis_data.py\n    \u2514\u2500\u2500 \ud83d\udcc4 jwt_manager.py\n\ud83d\udcc1 docs/\n\u2514\u2500\u2500 \ud83d\udcc1 imgs/\n    \u2514\u2500\u2500 \ud83d\udcc4 ...\n\ud83d\udcc4 .env\n\ud83d\udcc4 .gitignore\n\ud83d\udcc4 compose.yml\n</code></pre>"},{"location":"projeto/documentacao/#endpoints","title":"Endpoints","text":""},{"location":"projeto/documentacao/#registrar-usuario","title":"Registrar Usu\u00e1rio","text":"<ul> <li>URL: <code>/registrar</code></li> <li>M\u00e9todo: <code>POST</code></li> <li>Descri\u00e7\u00e3o: Registra um novo usu\u00e1rio no banco de dados.</li> <li>Par\u00e2metros:<ul> <li><code>user</code> (UserCreate): Informa\u00e7\u00f5es do usu\u00e1rio a ser registrado.</li> <li><code>db</code> (AsyncSession, opcional): A base de dados da sess\u00e3o, fornecido pela depend\u00eancia <code>Depends(get_database)</code>, com a depend\u00eancia Default <code>Depends(db)</code>.</li> </ul> </li> <li>Retorno:<ul> <li><code>Token</code>: O token JWT para o usu\u00e1rio registrado.</li> </ul> </li> <li>Erros:<ul> <li><code>400</code>: Email j\u00e1 registrado.</li> <li><code>400</code>: Nome indispon\u00edvel.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#login","title":"Login","text":"<ul> <li>URL: <code>/login</code></li> <li>M\u00e9todo: <code>POST</code></li> <li>Descri\u00e7\u00e3o: Lida com o login do usu\u00e1rio, verificando as credenciais e gerando um token JWT.</li> <li>Par\u00e2metros:<ul> <li><code>user</code> (UserLogin): Dados de login do usu\u00e1rio contendo email e senha.</li> <li><code>db</code> (AsyncSession, opcional): A base de dados da sess\u00e3o, fornecido pela depend\u00eancia <code>Depends(get_database)</code>, com a depend\u00eancia Default <code>Depends(db)</code>.</li> </ul> </li> <li>Retorno:<ul> <li><code>Token</code>: Um token JWT se o login for bem-sucedido.</li> </ul> </li> <li>Erros:<ul> <li><code>401</code>: Credenciais inv\u00e1lidas.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#consultar-dados","title":"Consultar Dados","text":"<ul> <li>URL: <code>/consultar</code></li> <li>M\u00e9todo: <code>GET</code></li> <li>Descri\u00e7\u00e3o: Valida um token e retorna os dados dos jogadores do Grepolis em formato HTML.</li> <li>Par\u00e2metros:<ul> <li><code>payload</code> (dict): O token a ser validado. Este \u00e9 fornecido pela depend\u00eancia <code>Depends(validate_token)</code>.</li> </ul> </li> <li>Retorno:<ul> <li><code>HTMLResponse</code>: Cont\u00e9m os dados dos jogadores do Grepolis em formato HTML.</li> </ul> </li> <li>Erros:<ul> <li><code>403</code>: Token inv\u00e1lido ou expirado.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#health-check","title":"Health Check","text":"<ul> <li>URL: <code>/health-check</code></li> <li>M\u00e9todo: <code>GET</code></li> <li>Descri\u00e7\u00e3o: Verifica o status do servidor.</li> <li>Retorno:<ul> <li><code>dict</code>: Um dicion\u00e1rio contendo o hostname do servidor.</li> <li><code>200</code>: Solicita\u00e7\u00e3o processada com sucesso e o servidor funcionando corretamente.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#modelos","title":"Modelos","text":""},{"location":"projeto/documentacao/#usercreate","title":"UserCreate","text":"<ul> <li>Descri\u00e7\u00e3o: Modelo Pydantic usado para criar um novo usu\u00e1rio.</li> <li>Atributos:<ul> <li><code>nome</code> (str): Nome do usu\u00e1rio.</li> <li><code>email</code> (str): Endere\u00e7o de email do usu\u00e1rio.</li> <li><code>senha</code> (str): Senha do usu\u00e1rio.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#userlogin","title":"UserLogin","text":"<ul> <li>Descri\u00e7\u00e3o: Modelo Pydantic para informa\u00e7\u00f5es de login do usu\u00e1rio.</li> <li>Atributos:<ul> <li><code>email</code> (str): Endere\u00e7o de email do usu\u00e1rio.</li> <li><code>senha</code> (str): Senha do usu\u00e1rio.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#token","title":"Token","text":"<ul> <li>Descri\u00e7\u00e3o: Modelo representando um JSON Web Token (JWT).</li> <li>Atributos:<ul> <li><code>jwt</code> (str): O token JWT como uma string.</li> </ul> </li> </ul>"},{"location":"projeto/documentacao/#como-executar","title":"Como executar","text":"<ol> <li> <p>Crie um arquivo <code>docker-compose.yml</code> com o seguinte conte\u00fado:     <pre><code>services:\n  app:\n    image: peng1104/projeto_cloud:v1.0.5\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - ./app:/app\n    env_file:\n      - .env\n    depends_on:\n      - database\n\n  database:\n    image: postgres:latest\n    restart: always\n    env_file:\n      - .env\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n\nvolumes:\n  postgres-data:\n</code></pre></p> </li> <li> <p>Configure as vari\u00e1veis de ambiente no arquivo <code>.env</code>. </p> <p>Exemplo: <pre><code>POSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_DB=db_app\nPOSTGRES_USER=humberto\nPOSTGRES_PASSWORD=gabriela\n\nAPP_PORT=8080\nJWT_SECRET=750fc55c0a404f8485580fd4bbcf6d7e\n</code></pre></p> </li> <li> <p>Execute a aplica\u00e7\u00e3o:     <pre><code>docker run --env-file .env -p 8080:8080 peng1104/projeto_cloud:v1.0.5\n</code></pre></p> </li> </ol>"},{"location":"projeto/documentacao/#docker","title":"Docker","text":"<p>Voc\u00ea tamb\u00e9m pode executar a aplica\u00e7\u00e3o usando Docker:</p> <ol> <li>Construa a imagem Docker:     <pre><code>docker build -t projeto_cloud .\n</code></pre></li> <li>Execute os containers usando Docker Compose:     <pre><code>docker-compose up\n</code></pre></li> </ol>"},{"location":"projeto/documentacao/#publicacao-no-docker","title":"Publica\u00e7\u00e3o no Docker","text":"<p>Para publicar a imagem no Docker Hub, foram ultilizados os seguintes comandos:</p> <ol> <li> <p>Fa\u00e7a login no Docker Hub:   <pre><code>docker login\n</code></pre></p> </li> <li> <p>Construa a imagem Docker:   <pre><code>docker build -t peng1104/projeto_cloud:v1.0.5 .\n</code></pre></p> </li> <li> <p>Fa\u00e7a o push da imagem para o Docker Hub:   <pre><code>docker push peng1104/projeto_cloud:v1.0.5\n</code></pre></p> </li> </ol> <p>Certifique-se de substituir <code>seu_usuario_docker</code> pelo seu nome de usu\u00e1rio no Docker Hub.</p>"},{"location":"projeto/documentacao/#imagem-docker","title":"Imagem Docker","text":"<p>Imagem Docker do projeto dispon\u00edvel em: peng1104/projeto_cloud</p>"},{"location":"projeto/documentacao/#screenshots-dos-endpoints","title":"Screenshots dos Endpoints","text":""},{"location":"projeto/documentacao/#tela-de-registro","title":"Tela de Registro","text":"<p>Figura 1 - Endpoint de registro.</p>"},{"location":"projeto/documentacao/#tela-de-login","title":"Tela de Login","text":"<p>Figura 2 - Endpoint de login.</p>"},{"location":"projeto/documentacao/#tela-de-consulta","title":"Tela de Consulta","text":"<p>Figura 3 - Endpoint de consulta.</p>"},{"location":"projeto/documentacao/#etapa-2","title":"ETAPA 2","text":""},{"location":"projeto/documentacao/#o-que-foi-feito_1","title":"O que foi feito?","text":"<p>Nesta Etapa 2, a aplica\u00e7\u00e3o desenvolvida na Etapa 1 foi implantada utilizando o AWS Lightsail Container Service. Al\u00e9m disso, foi configurado um banco de dados gerenciado no Lightsail, que foi conectado \u00e0 aplica\u00e7\u00e3o de forma segura.</p> <p>Para que a aplica\u00e7\u00e3o consiga se comunicar corretamente com o banco de dados, \u00e9 necess\u00e1rio fornecer as informa\u00e7\u00f5es de conex\u00e3o (como host, porta, usu\u00e1rio, senha e nome do banco) por meio de vari\u00e1veis de ambiente.</p> <p>Essas vari\u00e1veis s\u00e3o utilizadas no c\u00f3digo da aplica\u00e7\u00e3o para estabelecer a conex\u00e3o com o banco de forma din\u00e2mica, sem necessidade de deixar dados sens\u00edveis (como senhas) diretamente no c\u00f3digo-fonte.</p> <p>Al\u00e9m disso, como tanto a aplica\u00e7\u00e3o quanto o banco est\u00e3o hospedados no Lightsail e configurados para estarem na mesma rede privada, essa comunica\u00e7\u00e3o ocorre de forma mais segura e eficiente, sem exposi\u00e7\u00e3o p\u00fablica dos servi\u00e7os.</p> Exemplo mostrado na etapa anterior<pre><code>POSTGRES_HOST=postgres   --&gt; Hostname do banco de dados no servi\u00e7o do Lightsail\nPOSTGRES_PORT=5432   --&gt; Porta padr\u00e3o do PostgreSQL\nPOSTGRES_DB=db_app   --&gt; Nome do banco de dados criado\nPOSTGRES_USER=humberto   --&gt; Usu\u00e1rio autorizado a acessar o banco\nPOSTGRES_PASSWORD=gabriela   --&gt; Senha do usu\u00e1rio do banco\n\nAPP_PORT=8080   --&gt; Porta em que a aplica\u00e7\u00e3o ser\u00e1 executada no container\nJWT_SECRET=750fc55c0a404f8485580fd4bbcf6d7e   --&gt; Semente para gerar as chaves\n</code></pre>"},{"location":"projeto/documentacao/#como-executar_1","title":"Como executar","text":"<p>Autenticado na conta AWS e acessando o console do AWS Lightsail, foram seguidos os passos abaixo para executar a aplica\u00e7\u00e3o:</p> <ol> <li> <p>Criando o banco de dados:</p> <ul> <li>Banco de dados -&gt; Criar banco de dados</li> <li>Selecionado PostgreSQL, a regi\u00e3o desejada e o plano</li> <li>Definido o nome do banco, usu\u00e1rio e a senha</li> <li>Anotado o endpoint interno do banco para utilizar como POSTGRES_HOST</li> <li>Aguardando at\u00e9 o banco estar pronto</li> </ul> </li> <li> <p>Criando o servi\u00e7o de container:</p> <ul> <li>Containers -&gt; Criar servi\u00e7o de container</li> <li>Escolhida a imagem da aplica\u00e7\u00e3o do Docker Hub</li> <li>Definido o n\u00famero de containers e a porta de escuta</li> <li>No campo vari\u00e1veis de ambiente, inseridas as vari\u00e1veis do .env</li> <li>Finalizada a cria\u00e7\u00e3o do servi\u00e7o</li> </ul> </li> </ol>"},{"location":"projeto/documentacao/#screenshots-dos-endpoints_1","title":"Screenshots dos Endpoints","text":""},{"location":"projeto/documentacao/#tela-de-registro_1","title":"Tela de Registro","text":"<p>Figura 4 - Endpoint de registro na AWS.</p>"},{"location":"projeto/documentacao/#tela-de-consulta_1","title":"Tela de Consulta","text":"<p>Figura 5 - Endpoint de consulta na AWS.</p>"},{"location":"projeto/documentacao/#tela-de-checagem-da-saude","title":"Tela de Checagem da sa\u00fade","text":"<p>Figura 6 - Endpoint de sa\u00fade, mostrando funcionamento do load balance.</p>"},{"location":"projeto/documentacao/#screenshot-da-infraestrutura-funcionando-na-aws","title":"Screenshot da infraestrutura funcionando na AWS","text":""},{"location":"projeto/documentacao/#tela-demonstrando-funcionamento-da-aplicacao","title":"Tela demonstrando funcionamento da aplica\u00e7\u00e3o","text":"<p>Figura 7 - Aplica\u00e7\u00e3o funcionando.</p>"},{"location":"projeto/documentacao/#tela-demonstrando-a-base-de-dados","title":"Tela demonstrando a base de dados","text":"<p>Figura 8 - Base de dados.</p>"},{"location":"projeto/documentacao/#custos","title":"Custos","text":"<p>A seguir temos a Figura 9 com os pre\u00e7os dos containers de diferentes tamanhos.</p> <p></p> <p>Figura 9 - Custo dos containers.</p> <p>A decis\u00e3o foi de utilizar containers Nano, os quais possuem pre\u00e7o de 7 USD. O pre\u00e7o \u00e9 linear, com um acr\u00e9scimo de 7 USD a cada novo container, a utiliza\u00e7\u00e3o de 2 containers nesse projeto leva a um custo de 14 USD por m\u00eas (Figura 10).</p> <p></p> <p>Figura 10 - Custo dos 2 containers no projeto.</p> Consultar pre\u00e7os <p>Para mais informa\u00e7\u00f5es sobre os pre\u00e7os, consultar: https://aws.amazon.com/pt/lightsail/pricing/</p> Proje\u00e7\u00e3o <p>Fazendo uma proje\u00e7\u00e3o do custo para 1, 5 e 10 inst\u00e2ncias de containers, chegamos nos dados da Tabela 1 a seguir:</p> N\u00ba de containers Valor 1 7 USD 5 35 USD 10 70 USD <p>Tabela 1 - Proje\u00e7\u00e3o de pre\u00e7os.</p> <p>Agora, levando em considera\u00e7\u00e3o que \u00e9 utilizado um banco de dados, \u00e9 apresentada a Figura 11, sendo adotado o Plano Standard de 15 USD por m\u00eas.</p> <p>Todas as escolhas de containers e banco de dados feitas s\u00e3o explicadas por serem os planos mais baratos que atendem \u00e0s necessidades do projeto.</p> <p>Custos do projeto:</p> Valor 2 containers 14 USD 1 banco 15 USD TOTAL 29 USD <p>Tabela 2 - Custos do projeto. </p> <p>O custo da conta no dia da submiss\u00e3o \u00e9 mostrado na Figura 12 abaixo:</p> <p></p> <p>Figura 12 - Custo final da conta.</p>"},{"location":"projeto/documentacao/#arquitetura-final","title":"Arquitetura final","text":"<pre><code>flowchart LR\n    subgraph private [escrever]\n        direction TB\n        lb e3@==&gt; api1[\"&lt;div&gt;API 1&lt;br&gt;porta:8080&lt;/div&gt;\"]\n        lb e4@==&gt; api2[\"&lt;div&gt;API 2&lt;br&gt;porta:8080&lt;/div&gt;\"]\n        api1 e5@==&gt; db\n        api2 e6@==&gt; db\n    end\n    https[\"&lt;div&gt;HTTPS&lt;br&gt;porta:443&lt;/div&gt;\"] e1@==&gt; http\n    http[\"&lt;div&gt;HTTP&lt;br&gt;porta:80&lt;/div&gt;\"] e2@==&gt; lb\n    e1@{ animate: true }\n    e2@{ animate: true }\n    e3@{ animate: true }\n    e4@{ animate: true }\n    e5@{ animate: true }\n    e6@{ animate: true }\n    lb@{ shape: div-rect, label: \"Load Balancer\\nporta:80\" }\n    db@{ shape: cyl, label: \"PostgreSQL\\nporta:5432\" }</code></pre>"},{"location":"projeto/documentacao/#videos-demonstrativos","title":"Videos demonstrativos","text":"<p>Aqui est\u00e3o dois v\u00eddeos demonstrativos das Etapas 1 e 2 do projeto:</p> <p>V\u00eddeo 1 - Etapa 1 do projeto.</p> <p>V\u00eddeo 2 - Etapa 2 do projeto.</p>"},{"location":"projeto/enunciado/","title":"Enunciado","text":"<p>Enunciado original</p> <p>O enunciado completo do projeto se encontra na p\u00e1gina da disciplina no link: https://insper.github.io/computacao-nuvem/projetos_2025-1/projeto/</p> <p>O projeto trata de uma API RESTful que deve ser capaz de cadastrar e autenticar usu\u00e1rios, al\u00e9m de permitir a consulta de dados de terceiros. Ap\u00f3s a constru\u00e7\u00e3o da API, o projeto deve ser dockerizado e, ent\u00e3o, implantado na AWS.</p>"},{"location":"projeto/enunciado/#etapa-1","title":"Etapa 1","text":""},{"location":"projeto/enunciado/#construcao-da-api","title":"Constru\u00e7\u00e3o da API","text":"<p>A API dever ter no m\u00ednimo 3 endpoints:</p> Registro de Usu\u00e1rio Endpoint<pre><code>POST /registrar\n</code></pre> <p>Request JSON payload<pre><code>{\n    \"nome\": \"Disciplina Cloud\",\n    \"email\": \"cloud@insper.edu.br\",\n    \"senha\": \"cloud0\"\n}\n</code></pre></p> <p>Response JSON payload<pre><code>{\n    \"jwt\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkRpc2NpcGxpbmEgQ2xvdWQiLCJpYXQiOjE1MTYyMzkwMjJ9.s76o9X4UIANSI-aTF8UhqnBYyIRWw_WH4ut8Xqmo6i0\"\n}\n</code></pre></p> Autentica\u00e7\u00e3o de Usu\u00e1rio Endpoint<pre><code>POST /login\n</code></pre> <p>Request JSON payload<pre><code>{\n    \"email\": \"cloud@insper.edu.br\",\n    \"senha\": \"cloud0\"\n}\n</code></pre></p> <p>Response JSON payload<pre><code>{\n    \"jwt\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.\n            eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkRpc2N\n            pcGxpbmEgQ2xvdWQiLCJpYXQiOjE1MTYyMzkwMjJ9.\n            s76o9X4UIANSI-aTF8UhqnBYyIRWw_WH4ut8Xqmo6i0\"\n}\n</code></pre></p> Aquisi\u00e7\u00e3o dos Dados Endpoint<pre><code>GET /consultar\n\n### HEADER\nAuthorization: Bearer &lt;JWT&gt;\n</code></pre> <ul> <li> <p>Response: A resposta pode ser qualquer scrap de uma p\u00e1gina de terceiros, e o formato tamb\u00e9m pode ser qualquer um.</p> </li> <li> <p>Os dados devolvidos pela consulta devem ser de uma p\u00e1gina de terceiros, e devem ser atualizados frequentemente.</p> </li> <li> <p>Caso o usu\u00e1rio n\u00e3o tenha um token v\u00e1lido, a API deve retornar um erro 403.</p> </li> </ul>"},{"location":"projeto/enunciado/#dockerinzing","title":"Dockerinzing","text":"<p>Quando o c\u00f3digo da API estiver pronto, ele deve ser dockerizado. Para isso, deve-se criar um arquivo <code>Dockerfile</code> e um <code>compose.yaml</code> para a execu\u00e7\u00e3o da aplica\u00e7\u00e3o.</p> <p>O docker compose deve conter pelo menos 2 servi\u00e7os: a aplica\u00e7\u00e3o e o banco de dados. A aplica\u00e7\u00e3o deve ser capaz de se conectar ao banco de dados e realizar as opera\u00e7\u00f5es de CRUD.</p> <p>A aplica\u00e7\u00e3o deve ser autocontida, ou seja, deve ser poss\u00edvel executar a aplica\u00e7\u00e3o apenas com o comando <code>docker compose up</code> - pois isso \u00e9 parte essencial da entrega.</p> <p>Para organiza\u00e7\u00e3o:</p> estrutura de diret\u00f3rio sugerida<pre><code>\ud83d\udcc1 api/\n\u251c\u2500\u2500 \ud83d\udcc4 Dockerfile\n\u251c\u2500\u2500 \ud83d\udcc1 app/\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 app.py\n\u251c\u2500\u2500 \ud83d\udcc4 requirements.txt\n\u2514\u2500\u2500 \ud83d\udcc4 ...\n\ud83d\udcc4 compose.yaml\n\ud83d\udcc4 .env\n</code></pre>"},{"location":"projeto/enunciado/#publicacao-no-docker-hub","title":"Publica\u00e7\u00e3o no Docker Hub","text":"<p>Ap\u00f3s a dockeriza\u00e7\u00e3o, o projeto deve ser publicado no Docker Hub. O link do Docker Hub deve ser inclu\u00eddo na documenta\u00e7\u00e3o do projeto.</p> <p>A publica\u00e7\u00e3o no docker hub deve ser feita via linha de comando. E os comandos utilizados devem ser inclu\u00eddos na documenta\u00e7\u00e3o do projeto.</p> Vari\u00e1veis de Ambiente <p>As credenciais do banco de dados e JWT devem ser passadas via vari\u00e1veis de ambiente, por um arquivo <code>.env</code>. Todavia, PARA FACILITAR A CORRE\u00c7\u00c3O, as credenciais podem ser passadas diretamente no <code>compose.yaml</code> por valores padr\u00f5es, para que n\u00e3o tenha que haver um arquivo de vari\u00e1veis de ambiente. Exemplo:</p> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ul> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ul> .env<pre><code>POSTGRES_DB=meuprojeto\nPOSTGRES_USER=meuprojeto\nPOSTGRES_PASSWORD=S3cr3t\n</code></pre> <p>Ao executar, o docker compose ir\u00e1 utilizar as vari\u00e1veis de ambiente do arquivo <code>.env</code>, caso existam, sen\u00e3o, utilizar\u00e1 os valores padr\u00f5es definidos j\u00e1 dentro do arquivo <code>compose.yaml</code>.</p>"},{"location":"projeto/enunciado/#etapa-2","title":"Etapa 2","text":""},{"location":"projeto/enunciado/#aws-lightsail","title":"AWS Lightsail","text":"<p>Ap\u00f3s a conclus\u00e3o da etapa 1 do projeto com a aplica\u00e7\u00e3o containerizada localmente utilizando Docker Compose.</p> <p>Antes de iniciar, certifique-se de ter:</p> <ul> <li>Conta ativa na AWS com acesso ao Lightsail;</li> <li>Docker instalado e configurado;</li> <li>C\u00f3digo da aplica\u00e7\u00e3o FastAPI pronto e funcional localmente.</li> </ul> <p>Os pr\u00f3ximos passos s\u00e3o:</p> <ul> <li>Implantar a aplica\u00e7\u00e3o utilizando o AWS Lightsail Container Service;</li> <li>Configurar um banco de dados gerenciado no Lightsail;</li> <li>Conectar sua aplica\u00e7\u00e3o ao banco de dados;</li> <li>Gerenciar e monitorar o custo do servi\u00e7o em produ\u00e7\u00e3o.</li> </ul> Dicas <p>Para mais informa\u00e7\u00f5es sobre o Lightsail visualizar o conte\u00fado adicional na p\u00e1gina lightsail e para algumas dicas de configura\u00e7\u00e3o ver dicas.</p>"},{"location":"projeto/enunciado/#entregas","title":"Entregas","text":"Entrega Etapa 1 <p>A entrega dever\u00e1 ser um link do projeto no GitHub, contendo o c\u00f3digo da API e o Dockerfile, e deve haver uma documenta\u00e7\u00e3o b\u00e1sica do projeto no MkDocs, contendo:</p> <ul> <li>explica\u00e7\u00e3o do projeto - scrap do que foi feito;</li> <li>explica\u00e7\u00e3o de como executar a aplica\u00e7\u00e3o;</li> <li>documenta\u00e7\u00e3o dos endpoints da API;</li> <li>screenshot com os endpoints testados;</li> <li>video de execu\u00e7\u00e3o da aplica\u00e7\u00e3o - de at\u00e9 1 minuto;</li> <li>link para o docker hub do projeto;</li> <li>refer\u00eancia expl\u00edcita a localiza\u00e7\u00e3o do arquivo <code>compose.yaml</code>;</li> <li>o arquivo <code>compose.yaml</code> FINAL (entregue) deve utilizar apenas images do docker hub (inclusive as geradas para a api), ou seja, n\u00e3o deve ter build dentro dele.</li> </ul> Entrega Etapa 2 <p>A entrega dever\u00e1 ser um link do projeto no GitHub, contendo al\u00e9m do entregue antes (o c\u00f3digo da API e o Dockerfile), e deve haver uma documenta\u00e7\u00e3o b\u00e1sica do projeto no MkDocs, contendo:</p> <ul> <li>explica\u00e7\u00e3o do projeto - scrap do que foi feito;</li> <li>explica\u00e7\u00e3o de como executar a aplica\u00e7\u00e3o;</li> <li>screenshot com os endpoints AWS testados;</li> <li>screenshot da infraestrutura funcionando na AWS;</li> <li>tela dos custos da conta no mesmo dia da submiss\u00e3o dos documentos;</li> <li>video de execu\u00e7\u00e3o da aplica\u00e7\u00e3o funcionando no Ligthsail - de at\u00e9 1 minuto mostrando o acesso e a grava\u00e7\u00e3o de dados no banco de dados em Cloud;</li> <li>para conceito B, na documenta\u00e7\u00e3o dos custos deve ser projetado para: 1, 5 e 10 instancias de containers;</li> </ul>"},{"location":"projeto/enunciado/#rubrica","title":"Rubrica","text":"Rubrica Crit\u00e9rio Observa\u00e7\u00f5es FastAPI funcional com Docker Compose e banco local (PostgreSQL ou MySQL) App sobe com <code>docker-compose up</code>, banco acess\u00edvel pela aplica\u00e7\u00e3o Imagem publicada no Docker Hub e projeto organizado (<code>.env</code>, <code>.dockerignore</code>, estrutura clara) Demonstra conhecimento m\u00ednimo em containeriza\u00e7\u00e3o Documenta\u00e7\u00e3o m\u00ednima local (<code>README.md</code>) Instru\u00e7\u00f5es para build e execu\u00e7\u00e3o, com informa\u00e7\u00f5es da aplica\u00e7\u00e3o Deploy funcional no AWS Lightsail Containers App acess\u00edvel publicamente via URL fornecida pela AWS Banco de dados gerenciado no Lightsail funcionando e conectado \u00e0 aplica\u00e7\u00e3o Uso correto de vari\u00e1veis de ambiente, sem <code>localhost</code> no backend Documenta\u00e7\u00e3o da etapa na nuvem com instru\u00e7\u00f5es b\u00e1sicas de deploy Link de acesso + descri\u00e7\u00e3o do processo de publica\u00e7\u00e3o N\u00e3o estourar o custo mensal da infraestrutura que deve ser \u2264 USD 50 Custo estimado com base nos planos usados, infra\u00e7\u00e3o detalhada abaixo. Conceito C = Aprovado se todas as partes funcionarem e forem documentadas Projeto m\u00ednimo completo e compreens\u00edvel com as entregas 1 e 2 feitas Entregar o Conceito C ------------ Apresentar a arquitetura final do projeto em diagrama Indicar os componentes: app, container, banco, rede, dom\u00ednio Informar corretamente os recursos alocados (plano Lightsail, RAM, CPU, tipo do DB) Pode ser um par\u00e1grafo ou print com descri\u00e7\u00e3o dos planos usados Estimar o custo mensal da infraestrutura (\u2264 USD 50) Custo estimado com base nos planos usados, pode ser por texto ou print Conceito B = Aluno demonstra clareza na arquitetura e planejamento do uso de nuvem A entrega vai al\u00e9m da execu\u00e7\u00e3o, com compreens\u00e3o de recursos e custos Entregar o Conceito B ------------ Documenta\u00e7\u00e3o detalhada (ex: imagens do Lightsail, MkDocs, explica\u00e7\u00e3o clara do fluxo) Entrega cuidadosa e bem comunicada Explica\u00e7\u00e3o sobre a integra\u00e7\u00e3o app \u2194 banco (host, porta, seguran\u00e7a, vari\u00e1veis) Demonstra dom\u00ednio t\u00e9cnico da arquitetura e da integra\u00e7\u00e3o Banco de Dados instalado em Instancia no Ligthsail e conectado a aplica\u00e7\u00e3o Demonstra dom\u00ednio adicional sobre a arquitetura e produ\u00e7\u00e3o Conceito A = Entrega clara, comunicada, com dom\u00ednio da solu\u00e7\u00e3o em nuvem Mostra que o aluno sabe o que fez, como funciona e quanto custa"},{"location":"projeto/enunciado/#docker-compose","title":"Docker compose","text":""},{"location":"projeto/enunciado/#material-de-aula","title":"Material de aula","text":"estrutura para dois containers num mesmo compose<pre><code>api\n  Dockerfile\nweb\n  Dockerfile\n  hello.txt\n.env\ncompose.yaml\n</code></pre>"},{"location":"projeto/enunciado/#comandos","title":"Comandos","text":"<ul> <li> <p>Executando o docker compose: <pre><code>docker compose up -d --build\n</code></pre></p> </li> <li> <p>Parando o docker compose: <pre><code>docker compose down\n</code></pre></p> </li> </ul>"},{"location":"roteiros/roteiro1/main/","title":"Roteiro","text":""},{"location":"roteiros/roteiro1/main/#objetivo","title":"Objetivo","text":"<p>O objetivo principal desse roteiro \u00e9:</p> <ul> <li>entender os conceitos b\u00e1sicos sobre uma plataforma de gerenciamento de hardware</li> <li>introduzir conceitos b\u00e1sicos sobre redes de computadores</li> </ul>"},{"location":"roteiros/roteiro1/main/#roteiro","title":"Roteiro","text":"<p>Para visualizar o arquivo PDF feito e entregue, consultar o link a seguir: Roteiro 1 - PDF.</p>"},{"location":"roteiros/roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Warning</p> <p>O formato e a quantidade de tarefas do roteiro feito (em 2024.2) \u00e9 diferente do enunciado (de 2025.1), por\u00e9m coment\u00e1rios s\u00e3o feitos para melhor compreens\u00e3o e \u00e9 majoritariamente seguido o mesmo conte\u00fado.</p>"},{"location":"roteiros/roteiro1/main/#infra","title":"Infra","text":"<p>Para criar a infraestrutura, foram instalados o Ubuntu e o MaaS, realizando todas as configura\u00e7\u00f5es necess\u00e1rias.</p>"},{"location":"roteiros/roteiro1/main/#parte-i","title":"Parte I","text":"<p>Deploy do Ubuntu, instalar a aplica\u00e7\u00e3o PostgreSQL e criar uma base de dados.</p> Tarefa-1 <p>Estude os comandos ping, ifconfig, systemctl, telnet, ufw, curl, wget e journalctl. Com estes comandos apresente prints das Telas  que provam que o banco de dados est\u00e1:</p> <pre><code>1. Funcionando e seu Status est\u00e1 como \"Ativo\" para o Sistema Operacional\n2. Acessivel na pr\u00f3pria maquina na qual ele foi implantado.\n3. Acessivel a partir de uma conex\u00e3o vinda da m\u00e1quina MAIN.\n4. Em qual porta este servi\u00e7o est\u00e1 funcionando.\n</code></pre> <p>No roteiro que fizemos essas telas n\u00e3o foram requeridas.</p>"},{"location":"roteiros/roteiro1/main/#parte-ii","title":"Parte II","text":"<p>Subir uma aplica\u00e7\u00e3o Django. </p> Tarefa-2 <p>De um print das Telas abaixo:</p> <pre><code>1. Do Dashboard do **MAAS** com as m\u00e1quinas.\n2. Da aba images, com as imagens sincronizadas.\n3. Da Aba de cada maquina(5x) mostrando os testes de hardware e commissioning com Status \"OK\"\n</code></pre> <p></p> <p>Figura 1 - Painel Django acessado via tunelamento </p> <p></p> <p>Figura 2 - Dashboard do MAAS com as m\u00e1quinas </p> <p></p> <p>Figura 3 - Aba imagens, com as imagens sincronizadas</p> <p></p> <p>Figura 4 - Server 1: Network</p> <p></p> <p>Figura 5 - Server 1: Commissioning </p> <p></p> <p>Figura 6 - Server 1: Testes </p> <p></p> <p>Figura 7 - Server 2: Network </p> <p></p> <p>Figura 8 - Server 2: Commissioning</p> <p></p> <p>Figura 9 - Server 2: Testes </p> <p></p> <p>Figura 10 - Server 3: Network</p> <p></p> <p>Figura 11 - Server 3: Commissioning</p> <p></p> <p>Figura 12 - Server 3: Tests</p> <p></p> <p>Figura 13 - Server 4: Network </p> <p></p> <p>Figura 14 - Server 4: Commissioning </p> <p></p> <p>Figura 15 - Server 4: Tests  </p> <p></p> <p>Figura 16 - Server 5: Network </p> <p></p> <p>Figura 17 - Server 5: Comissioning  </p> <p></p> <p>Figura 18 - Server 5: Tests </p> <p>Utilizando o Ansible - deploy automatizado de aplica\u00e7\u00e3o.</p> Tarefa-3 <ol> <li>De um print da tela do Dashboard do MAAS com as 2 Maquinas e seus respectivos IPs.</li> <li>De um print da aplicacao Django, provando que voce est\u00e1 conectado ao server </li> <li>Explique como foi feita a implementacao manual da aplicacao Django e banco de dados.</li> </ol> <p>No roteiro que fizemos, ESSA TAREFA FOI PEDIDA NO ROTEIRO 2, mas colocamos as respostas abaixo: </p> <p></p> <p>Figura 19 - Dashboard do MAAS com as 2 m\u00e1quinas </p> <p></p> <p>Figura 20 - Painel Django acessado via tunelamento </p> <p>Explique como foi feita a implementa\u00e7\u00e3o manual da aplica\u00e7\u00e3o Django e banco de dados.</p> <p>Fazer toda a conex\u00e3o com o MAAS e logar no MAAS, para poder conectar \u00e0 m\u00e1quina e realizar seu deploy. Depois, fazer git clone e install para deixar o ambiente django pronto para o seu uso. </p> <p>Subindo uma aplica\u00e7\u00e3o Django utilizando o Ansible.</p> Tarefa-4 <p>Teste o acesso, caso esteja tudo certo, fa\u00e7a a tarefa abaixo</p> <pre><code>1. De um print da tela do Dashboard do MAAS com as 3 Maquinas e seus respectivos IPs.\n2. De um print da aplicacao Django, provando que voce est\u00e1 conectado ao server2 \n3. De um print da aplicacao Django, provando que voce est\u00e1 conectado ao server3 \n4. Explique qual diferenca entre instalar manualmente a aplicacao Django e utilizando o Ansible.\n</code></pre> <p>No roteiro que fizemos, ESSA TAREFA FOI PEDIDA NO ROTEIRO 2, mas colocamos as respostas abaixo:</p> <p></p> <p>Figura 21 - Dashboard do MAAS com as 3 m\u00e1quinas </p> <p></p> <p>Figura 22 - Aplica\u00e7\u00e3o Django provando que est\u00e1 conectado ao Server 2 </p> <p></p> <p>Figura 23 - Aplica\u00e7\u00e3o Django provando que est\u00e1 conectado ao Server 3 </p> <p>Explique  qual  a  diferen\u00e7a  entre  instalar  manualmente  a  aplica\u00e7\u00e3o  Django  e utilizando o Ansible.</p> <p>A diferen\u00e7a \u00e9 que, com o deploy feito no server, pode-se usar o Ansible para preparar o ambiente para a aplica\u00e7\u00e3o do django.</p> <p>Balanceamento de carga usando Proxy Reverso, \u00e9 instalando o nginx.</p> Tarefa-5 <p>Teste o acesso, caso esteja tudo certo, fa\u00e7a a tarefa abaixo:</p> <pre><code>1. De um print da tela do Dashboard do MAAS com as 4 Maquinas e seus respectivos IPs.\n2. Altere o conte\u00fado da mensagem contida na fun\u00e7\u00e3o `index` do arquivo `tasks/views.py` de cada server para distinguir ambos os servers. \n3. Fa\u00e7a um `GET request` para o path que voce criou em urls.py para o Nginx e tire 2 prints das respostas de cada request, provando que voce est\u00e1 conectado ao server 4, que \u00e9 o Proxy Reverso e que ele bate cada vez em um server diferente server2 e server3.\n</code></pre> <p>No roteiro que fizemos, ESSA TAREFA FOI PEDIDA NO ROTEIRO 2, mas colocamos as respostas abaixo:</p> <p></p> <p>Figura 24 - Dashboard do MAAS com as 4 m\u00e1quinas</p> <p></p> <p>Figura 25 - Resposta do request conectado ao Server2 </p> <p></p> <p>Figura 26 - Resposta do request conectado ao Server3 </p> <p>Agora finalizando, \u00e9 feito um release de todos os n\u00f3s no kit.</p>"},{"location":"roteiros/roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Este roteiro aborda o provisionamento e gerenciamento de infraestrutura Bare Metal com MaaS, permitindo tratar servidores f\u00edsicos como uma nuvem privada. A instala\u00e7\u00e3o do PostgreSQL garante maior controle sobre o desempenho e seguran\u00e7a do banco de dados, essencial para aplica\u00e7\u00f5es de grande porte.</p> <p>O uso do Ansible automatiza o deploy da aplica\u00e7\u00e3o Django, refor\u00e7ando a import\u00e2ncia da infraestrutura como c\u00f3digo (IaC) para padroniza\u00e7\u00e3o e efici\u00eancia operacional. Al\u00e9m disso, a implementa\u00e7\u00e3o do Nginx como proxy reverso melhora a escalabilidade e a disponibilidade da aplica\u00e7\u00e3o, distribuindo a carga de forma eficiente.</p> <p>O aprendizado adquirido refor\u00e7a pr\u00e1ticas essenciais de DevOps, automa\u00e7\u00e3o e escalabilidade para aplica\u00e7\u00f5es modernas.</p>"},{"location":"roteiros/roteiro2/main/","title":"Roteiro","text":""},{"location":"roteiros/roteiro2/main/#objetivo","title":"Objetivo","text":"<p>O objetivo principal desse roteiro \u00e9:</p> <ul> <li>entender os conceitos b\u00e1sicos sobre uma plataforma de gerenciamento de aplica\u00e7\u00f5es distribu\u00eddas</li> <li>entender os conceitos b\u00e1sicos de comunica\u00e7\u00e3o entre aplica\u00e7\u00f5es e servi\u00e7os</li> </ul>"},{"location":"roteiros/roteiro2/main/#roteiro","title":"Roteiro","text":"<p>Para visualizar o arquivo PDF feito e entregue, consultar o link a seguir: Roteiro 2 - PDF.</p>"},{"location":"roteiros/roteiro2/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Warning</p> <p>O formato e a quantidade de tarefas do roteiro feito (em 2024.2) \u00e9 diferente do enunciado (de 2025.1), por\u00e9m coment\u00e1rios s\u00e3o feitos para melhor compreens\u00e3o e \u00e9 majoritariamente seguido o mesmo conte\u00fado.</p>"},{"location":"roteiros/roteiro2/main/#infra","title":"Infra","text":"<p>Para criar a infraestrutura, foi instalado o Juju, realizando todas as configura\u00e7\u00f5es necess\u00e1rias.</p>"},{"location":"roteiros/roteiro2/main/#deployment-orchestration","title":"Deployment Orchestration","text":"<p>Instalados o Dashboard do Juju, o Grafana e o Prometheus, e \u00e9 feito o deploy das aplica\u00e7\u00f5es Grafana e Prometheus com o auxilio do Juju. Por fim, integra-se o Grafana com o Prometheus.</p> Tarefa-1 <ol> <li>De um print da tela do Dashboard do MAAS com as Maquinas e seus respectivos IPs.</li> <li>De um print de tela do comando \"juju status\" depois que o Grafana estiver \"active\". </li> <li>De um print da tela do Dashboard do Grafana com o Prometheus aparecendo como source.</li> <li>Prove (print) que voc\u00ea est\u00e1 conseguindo acessar o Dashboard a partir da rede do Insper.</li> <li>De um print na tela que mostra as aplica\u00e7\u00f5es sendo gerenciadas pelo JUJU (http://IP-Servi\u00e7o:8080/models/admin/maas)</li> </ol> <p>No roteiro que fizemos as telas dos pontos 4 e 5 n\u00e3o foram requeridas.</p> <p></p> <p>Figura 1 - Dashboard do MAAS com as m\u00e1quinas e seus respectivos IPs </p> <p></p> <p>Figura 2 - Comando \u201cjuju status\u201d com o Grafana ativo </p> <p></p> <p>Figura 3 - Dashboard do Grafana com o Prometheus aparecendo como source </p> <p></p> <p>Figura 4 - Comando do tunelamento com o Grafana </p>"},{"location":"roteiros/roteiro2/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Este roteiro demonstra o uso do Juju para orquestra\u00e7\u00e3o de deployment em infraestrutura Bare Metal, simplificando a configura\u00e7\u00e3o e gerenciamento de servi\u00e7os. A instala\u00e7\u00e3o do Juju Dashboard facilita a administra\u00e7\u00e3o visual da infraestrutura, melhorando a usabilidade e monitoramento.</p> <p>A utiliza\u00e7\u00e3o do Juju para implantar o Grafana e o Prometheus destaca a automa\u00e7\u00e3o no gerenciamento de aplica\u00e7\u00f5es, reduzindo a complexidade do deploy e garantindo consist\u00eancia na configura\u00e7\u00e3o. A integra\u00e7\u00e3o entre essas ferramentas permite a coleta e visualiza\u00e7\u00e3o de m\u00e9tricas em tempo real, essencial para a observabilidade e monitoramento eficaz da infraestrutura.</p>"},{"location":"roteiros/roteiro3/main/","title":"Roteiro","text":""},{"location":"roteiros/roteiro3/main/#objetivo","title":"Objetivo","text":"<p>O objetivo principal desse roteiro \u00e9:</p> <ul> <li>entender os conceitos b\u00e1sicos de Private Cloud</li> <li>aprofundar conceitos sobre redes virtuais SDN</li> </ul>"},{"location":"roteiros/roteiro3/main/#roteiro","title":"Roteiro","text":"<p>Para visualizar o arquivo PDF feito e entregue, consultar o link a seguir: Roteiro 3 - PDF.</p>"},{"location":"roteiros/roteiro3/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>O OpenStack \u00e9 um conjunto de componentes de software que oferecem servi\u00e7os comuns para a infraestrutura de cloud.</p> <p></p> <p>Figura 1 - OpenStack. Fonte: https://www.openstack.org/</p>"},{"location":"roteiros/roteiro3/main/#infra-nuvem-vm-servidor-virtual-privado-vps","title":"Infra (Nuvem VM) - Servidor Virtual Privado (VPS)","text":"<p>O OpenStack permitir\u00e1 distribuir virtual machines usando os n\u00f3s dispon\u00edveis no kit, mas antes de iniciar a instala\u00e7\u00e3o, deve-se verificar se o MAAS est\u00e1 configurado corretamente.</p> <p>A documenta\u00e7\u00e3o oficial do OpenStack est\u00e1 presente no link a seguir: Implanta\u00e7\u00e3o do OpenStack</p>"},{"location":"roteiros/roteiro3/main/#implantacao-do-openstack","title":"Implanta\u00e7\u00e3o do OpenStack","text":"<ul> <li>Nesse ambiente, o Juju controller deve estar instalado no server1;</li> <li>Para monitorar o status da instala\u00e7\u00e3o, usar o comando: <pre><code>watch -n 2 --color \"juju status --color\"\n</code></pre></li> </ul> <p>Erro de instala\u00e7\u00e3o</p> <p>No caso de problemas durante a instala\u00e7\u00e3o, dependendo da gravidade do problema, \u00e9 mais simples limpar a instala\u00e7\u00e3o:</p> <pre><code>juju kill-controller maas-controller\n</code></pre> <p>E reiniciar desde 1 - Juju Controller.</p> <p>Aviso</p> <p>O roteiro feito, em 2024.2, possui uma vers\u00e3o antiga dos comandos utilizados. Durante essa documenta\u00e7\u00e3o do roteiro, ser\u00e3o apresentados os comandos utilizados na realiza\u00e7\u00e3o do roteiro, e os comandos atualizados estar\u00e3o apresentados em notas intituladas Nova Vers\u00e3o.</p>"},{"location":"roteiros/roteiro3/main/#1-juju-controller","title":"1 - Juju Controller","text":"<p>Apenas se ainda n\u00e3o tiver um Juju Controller, adicionar a tag controller na m\u00e1quina server1:</p> <pre><code>juju bootstrap --bootstrap-series=jammy --constraints tags=controller maas-one maas-controller\n</code></pre>"},{"location":"roteiros/roteiro3/main/#2-modelo-de-deploy","title":"2 - Modelo de deploy","text":"<pre><code>juju add-model --config default-series=jammy openstack\njuju switch maas-controller:openstack\n</code></pre>"},{"location":"roteiros/roteiro3/main/#3-ceph-osd","title":"3 - Ceph OSD","text":"<p>O aplicativo ceph-osd \u00e9 implantado em 3 n\u00f3s usando o charm ceph-osd, com os dispositivos de armazenamento <code>/dev/sda</code> e <code>/dev/sdb</code> configurados para uso em todos os n\u00f3s no arquivo ceph-osd.yaml. \u00c9 utilizada a tag compute, definida previamente nos n\u00f3s via MAAS, com o comando juju deploy especificando as 3 m\u00e1quinas e a configura\u00e7\u00e3o das mesmas. Para fazer o deploy da aplica\u00e7\u00e3o ceph-osd:</p> <pre><code>juju deploy -n 3 --channel reef/stable --config ceph-osd.yaml --constraints tags=compute ceph-osd\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy -n 3 --channel quincy/stable --config ceph-osd.yaml --constraints tags=compute ceph-osd\n</code></pre>"},{"location":"roteiros/roteiro3/main/#4-nova-compute","title":"4 - Nova Compute","text":"<p>O nova-compute, respons\u00e1vel por provisionar inst\u00e2ncias de computa\u00e7\u00e3o no OpenStack, deve ser implantado nos n\u00f3s de computa\u00e7\u00e3o usando os IDs das m\u00e1quinas (1 e 2), pois n\u00e3o h\u00e1 mais n\u00f3s MAAS dispon\u00edveis. Isso implica em compartilhar os mesmos n\u00f3s entre m\u00faltiplos servi\u00e7os. \u00c9 feito o arquivo de configura\u00e7\u00e3o nova-compute.yaml, e para o deploy:</p> <pre><code>juju deploy -n 2 --to 1,2 --channel 2023.2/stable --config nova-compute.yaml nova-compute\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy -n 3 --to 0,1,2 --channel yoga/stable --config nova-compute.yaml nova-compute\n</code></pre>"},{"location":"roteiros/roteiro3/main/#5-mysql-innodb-cluster","title":"5 - MySQL InnoDB Cluster","text":"<p>MySQL InnoDB Cluster requer no m\u00ednimo 3 unidades de banco de dados, e ele deve implantado com o atributo mysql-innodb-cluster, sendo conteinerizados nas m\u00e1quinas 0, 1 e 2, fazendo o deploy como indicado:</p> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel 8.0/stable mysql-innodb-cluster\n</code></pre>"},{"location":"roteiros/roteiro3/main/#6-vault","title":"6 - Vault","text":"<p>O Vault gerencia os certificados TLS que permitem a comunica\u00e7\u00e3o criptografada entre aplicativos em nuvem, sendo conteinerizado:</p> <pre><code>juju deploy --to lxd:0 --channel 1.8/stable vault\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:2 vault --channel 1.8/stable\n</code></pre> <p>Os passos seguintes s\u00e3o de acordo com as intru\u00e7\u00f5es abaixo, com os seus respectivos comandos:</p> <ul> <li>criar inst\u00e2ncia espec\u00edfica do mysql-router com o charm subordinado mysql-router;</li> <li>adicionar rela\u00e7\u00e3o entre inst\u00e2ncia mysql-router e o banco de dados;</li> <li>adicionar rela\u00e7\u00e3o entre inst\u00e2ncia mysql-router e o aplicativo.</li> </ul> <pre><code>juju deploy --channel 8.0/stable mysql-router vault-mysql-router\njuju integrate vault-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate vault-mysql-router:shared-db vault:shared-db\n</code></pre> <p>Para o Vault ser inicializado, desbloqueado e autorizado, s\u00e3o executados os comandos a seguir com os seguintes prop\u00f3sitos:</p> <ul> <li>Instalando o cli do Vault;</li> <li>Configurando o cli;</li> <li>Gerando keys;</li> <li>Remover o selo de 3 teclas (usar esse comando 3 vezes);</li> <li>Confirgurando o token;</li> <li>Gerando um token (tempo dos pr\u00f3ximos passos: 10 minutos);</li> <li>Autorizando.</li> </ul> <pre><code>sudo snap install vault\nexport VAULT_ADDR=\"http://&lt;IP of vault&gt;:8200\"\nvault operator init -key-shares=5 -key-threshold=3\nvault operator unseal &lt;Unseal Key&gt;\nexport VAULT_TOKEN=&lt;Initial Root Token&gt;\nvault token create -ttl=10m\njuju run vault/0 authorize-charm token=&lt;Token generated in the last command&gt;\n</code></pre> Nova Vers\u00e3o <pre><code>juju run vault/leader authorize-charm token=&lt;Token generated in the last command&gt;\n</code></pre> <p>Para o Vault, \u00e9 preciso um certificado de CA autoassinado para que ele possa emitir os certificados para servi\u00e7os de API em nuvem.</p> <pre><code>juju run vault/0 generate-root-ca\n</code></pre> Nova Vers\u00e3o <pre><code>juju run vault/leader generate-root-ca\n</code></pre> <p>Os aplicativos em nuvem s\u00e3o habilitados para TLS por meio da rela\u00e7\u00e3o vault:certificates.</p> <pre><code>juju integrate mysql-innodb-cluster:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#7-neutron-networking","title":"7 - Neutron Networking","text":"<p>A rede de n\u00eautrons \u00e9 implementada com 4 aplica\u00e7\u00f5es, com o arquivo neutron.yaml configurando apenas as aplica\u00e7\u00f5es neutron-api e ovn-chassis, e com isso s\u00e3o feitos os deploys:</p> <ul> <li>ovn-central: no m\u00ednimo 3 unidades -&gt; conteinerizadas nas m\u00e1quinas 0, 1 e 2.</li> <li>neutron-api: conteinerizado na m\u00e1quina 1.</li> <li>neutron-api-plugin-ovn (subordinado): aplica\u00e7\u00e3o charm subordinada.</li> <li>ovn-chassis (subordinado): aplica\u00e7\u00e3o charm subordinada.</li> </ul> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel 23.09/stable ovn-central\njuju deploy --to lxd:1 --channel 2023.2/stable --config neutron.yaml neutron-api\njuju deploy --channel 2023.2/stable neutron-api-plugin-ovn\njuju deploy --channel 23.09/stable --config neutron.yaml ovn-chassis\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel 22.03/stable ovn-central\njuju deploy --to lxd:1 --channel yoga/stable --config neutron.yaml neutron-api\njuju deploy --channel yoga/stable neutron-api-plugin-ovn\njuju deploy --channel 22.03/stable --config neutron.yaml ovn-chassis\n</code></pre> <p>S\u00e3o adicionadas as rela\u00e7\u00f5es necess\u00e1rias:</p> <pre><code>juju integrate neutron-api-plugin-ovn:neutron-plugin neutron-api:neutron-plugin-api-subordinate\njuju integrate neutron-api-plugin-ovn:ovsdb-cms ovn-central:ovsdb-cms\njuju integrate ovn-chassis:ovsdb ovn-central:ovsdb\njuju integrate ovn-chassis:nova-compute nova-compute:neutron-plugin\njuju integrate neutron-api:certificates vault:certificates\njuju integrate neutron-api-plugin-ovn:certificates vault:certificates\njuju integrate ovn-central:certificates vault:certificates\njuju integrate ovn-chassis:certificates vault:certificates\n</code></pre> <p>Conectando a neutron-api ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router neutron-api-mysql-router\njuju integrate neutron-api-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate neutron-api-mysql-router:shared-db neutron-api:shared-db\n</code></pre>"},{"location":"roteiros/roteiro3/main/#8-keystone","title":"8 - Keystone","text":"<p>Aplica\u00e7\u00e3o Keystone conteinerizada na m\u00e1quina 0, com deploy: </p> <pre><code>juju deploy --to lxd:0 --channel 2023.2/stable keystone\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:0 --channel yoga/stable keystone\n</code></pre> <p>Conectando o Keystone ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router keystone-mysql-router\njuju integrate keystone-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate keystone-mysql-router:shared-db keystone:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate keystone:identity-service neutron-api:identity-service\njuju integrate keystone:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#9-rabbitmq","title":"9 - RabbitMQ","text":"<p>O aplicativo rabbitmq-server \u00e9 conteinerizado na m\u00e1quina 2 com o charm rabbitmq-server, adicionando em seguida duas rela\u00e7\u00f5es.</p> <pre><code>juju deploy --to lxd:2 --channel 3.9/stable rabbitmq-server\njuju integrate rabbitmq-server:amqp neutron-api:amqp\njuju integrate rabbitmq-server:amqp nova-compute:amqp\n</code></pre>"},{"location":"roteiros/roteiro3/main/#10-nova-cloud-controller","title":"10 - Nova Cloud Controller","text":"<p>Esse aplicativo \u00e9 conteinerizado na m\u00e1quina 2 com o charm nova-cloud-controller. \u00c9 feito o arquivo ncc.yaml, que cont\u00e9m as configura\u00e7\u00f5es, e depois \u00e9 feito o deploy da aplica\u00e7\u00e3o:</p> <pre><code>juju deploy --to lxd:2 --channel 2023.2/stable --config ncc.yaml nova-cloud-controller\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:2 --channel yoga/stable --config ncc.yaml nova-cloud-controller\n</code></pre> <p>Conectando o Nova Cloud Controller ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router ncc-mysql-router\njuju integrate ncc-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate ncc-mysql-router:shared-db nova-cloud-controller:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate nova-cloud-controller:identity-service keystone:identity-service\njuju integrate nova-cloud-controller:amqp rabbitmq-server:amqp\njuju integrate nova-cloud-controller:neutron-api neutron-api:neutron-api\njuju integrate nova-cloud-controller:cloud-compute nova-compute:cloud-compute\njuju integrate nova-cloud-controller:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#11-placement","title":"11 - Placement","text":"<p>A aplica\u00e7\u00e3o Placement \u00e9 conteinerizado com o charm placement.</p> <pre><code>juju deploy --to lxd:1 --channel 2023.2/stable placement\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:2 --channel yoga/stable placement\n</code></pre> <p>Conectando o Placement ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router placement-mysql-router\njuju integrate placement-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate placement-mysql-router:shared-db placement:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate placement:identity-service keystone:identity-service\njuju integrate placement:placement nova-cloud-controller:placement\njuju integrate placement:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#12-horizon-openstack-dashboard","title":"12 - Horizon - OpenStack Dashboard","text":"<p>O Horizon \u00e9 conteinerizado na m\u00e1quina 2 com o charm openstack-dashboard.</p> <pre><code>juju deploy --to lxd:2 --channel 2023.2/stable openstack-dashboard\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:2 --channel yoga/stable openstack-dashboard\n</code></pre> <p>Conectando o Horizon ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router dashboard-mysql-router\njuju integrate dashboard-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate dashboard-mysql-router:shared-db openstack-dashboard:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate openstack-dashboard:identity-service keystone:identity-service\njuju integrate openstack-dashboard:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#13-glance","title":"13 - Glance","text":"<p>A aplica\u00e7\u00e3o Glance \u00e9 conteinerizada na m\u00e1quina 2 com o charm glance.</p> <pre><code>juju deploy --to lxd:2 --channel 2023.2/stable glance\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:2 --channel yoga/stable glance\n</code></pre> <p>Conectando o Glance ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router glance-mysql-router\njuju integrate glance-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate glance-mysql-router:shared-db glance:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate glance:image-service nova-cloud-controller:image-service\njuju integrate glance:image-service nova-compute:image-service\njuju integrate glance:identity-service keystone:identity-service\njuju integrate glance:certificates vault:certificates\n</code></pre>"},{"location":"roteiros/roteiro3/main/#14-ceph-monitor","title":"14 - Ceph Monitor","text":"<p>O Ceph Monitor \u00e9 conteinerizado nas m\u00e1quinas 0, 1 e 2 com o charm ceph-mon. Primeiro \u00e9 feito o arquivo ceph-mon.yaml, que cont\u00e9m as configura\u00e7\u00f5es, e depois \u00e9 feito o deploy da aplica\u00e7\u00e3o:</p> <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel reef/stable --config ceph-mon.yaml ceph-mon\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy -n 3 --to lxd:0,lxd:1,lxd:2 --channel quincy/stable --config ceph-mon.yaml ceph-mon\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate ceph-mon:osd ceph-osd:mon\njuju integrate ceph-mon:client nova-compute:ceph\njuju integrate ceph-mon:client glance:ceph\n</code></pre>"},{"location":"roteiros/roteiro3/main/#15-cinder","title":"15 - Cinder","text":"<p>O Cinder \u00e9 conteinerizado na m\u00e1quina 1 com o charm cinder. \u00c9 criado o arquivo de configura\u00e7\u00e3o cinder.yaml, e depois \u00e9 feito o deploy da aplica\u00e7\u00e3o:</p> <pre><code>juju deploy --to lxd:1 --channel 2023.2/stable --config cinder.yaml cinder\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:1 --channel yoga/stable --config cinder.yaml cinder\n</code></pre> <p>Conectando o Cinder ao banco de dados na nuvem:</p> <pre><code>juju deploy --channel 8.0/stable mysql-router cinder-mysql-router\njuju integrate cinder-mysql-router:db-router mysql-innodb-cluster:db-router\njuju integrate cinder-mysql-router:shared-db cinder:shared-db\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate cinder:cinder-volume-service nova-cloud-controller:cinder-volume-service\njuju integrate cinder:identity-service keystone:identity-service\njuju integrate cinder:amqp rabbitmq-server:amqp\njuju integrate cinder:image-service glance:image-service\njuju integrate cinder:certificates vault:certificates\n</code></pre> <p>A rela\u00e7\u00e3o glance:image-service permite que o Cinder consuma a API do Glance e, como o Glance, o Cinder usa o ceph como backend de armazenamento, implementado com o comando subordinado a seguir:</p> <pre><code>juju deploy --channel 2023.2/stable cinder-ceph\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --channel yoga/stable cinder-ceph\n</code></pre> <p>Adicionando rela\u00e7\u00f5es:</p> <pre><code>juju integrate cinder-ceph:storage-backend cinder:storage-backend\njuju integrate cinder-ceph:ceph ceph-mon:client\njuju integrate cinder-ceph:ceph-access nova-compute:ceph-access\n</code></pre>"},{"location":"roteiros/roteiro3/main/#16-ceph-rados-gateway","title":"16 - Ceph RADOS Gateway","text":"<p>O Ceph RADOS Gateway, implantado para oferecer um gateway HTTP compat\u00edvel com S3 e Swift, \u00e9 conteinerizado na m\u00e1quina 0 com o charm ceph-radosgw.</p> <pre><code>juju deploy --to lxd:0 --channel reef/stable ceph-radosgw\n</code></pre> Nova Vers\u00e3o <pre><code>juju deploy --to lxd:0 --channel quincy/stable ceph-radosgw\n</code></pre> <p>Adicionando rela\u00e7\u00e3o:</p> <pre><code>juju integrate ceph-radosgw:mon ceph-mon:radosgw\n</code></pre>"},{"location":"roteiros/roteiro3/main/#17-ceph-osd-integration","title":"17 - Ceph-OSD Integration","text":"<p>Com todos os comandos anteriores corretamente realizados, \u00e9 preciso executar a configura\u00e7\u00e3o do charm ceph-osd para usar o dispositivo de bloco <code>/dev/sdb</code> como armazenamento para os OSDs do Ceph.</p> <pre><code>juju config ceph-osd osd-devices='/dev/sdb'\n</code></pre>"},{"location":"roteiros/roteiro3/main/#configurando-o-openstack","title":"Configurando o Openstack","text":"<ul> <li>Documenta\u00e7\u00e3o da refer\u00eancia oficial: https://docs.openstack.org/project-deploy-guide/charm-deployment-guide/latest/configure-openstack.html</li> </ul> <p>Ser\u00e3o configurados o servi\u00e7o que controla as VMs (Nova), os volumes de disco (Cinder), e a estrutura de rede virtual (Neutron). \u00c9 feita uma autentica\u00e7\u00e3o (Keystone) no sistema, \u00e9 montado o servidor de imagens (Glance), que utiliza o Object Storage (Ceph) para armazenamento, e conta com um dashboard (Horizon), um cluster de banco de dados (Mysql Inno Cluster) e um servidor de filas (RabbitMQ) como apoio.</p> <p>E para isso, ser\u00e3o seguidos os seguintes passos:</p>"},{"location":"roteiros/roteiro3/main/#passo-1-autenticacao","title":"Passo 1: Autentica\u00e7\u00e3o","text":"<p>Criando o arquivo <code>openrc</code> com as credenciais de acesso ao OpenStack.</p> <ul> <li> <p>Obtendo o endere\u00e7o IP: <pre><code>juju status --format=yaml openstack-dashboard | grep public-address | awk '{print $2}' | head -1\n</code></pre></p> </li> <li> <p>Obtendo a senha: <pre><code>juju run keystone/0 get-admin-password\n</code></pre></p> </li> </ul>"},{"location":"roteiros/roteiro3/main/#passo-2-horizon","title":"Passo 2: Horizon","text":"<p>Acessando o dashboard Horizon como administrador e mantendo ele aberto durante todo o setup do openstack para visualizar as mudan\u00e7as que est\u00e3o sendo feitas.</p> <ul> <li>Horizon_URL: https://#IP_obtido#/horizon</li> <li>User_Name: admin</li> <li>Password: #Senha_obtida#</li> <li>Domain_Name: admin_domain</li> </ul> Tarefa-1 <p>De um print das Telas abaixo:</p> <pre><code>1. Do Status do JUJU\n2. Do Dashboard do MAAS com as m\u00e1quinas.\n3. Da aba compute overview no OpenStack Dashboard.\n4. Da aba compute instances no OpenStack Dashboard.\n5. Da aba network topology no OpenStack Dashboard.\n</code></pre> <p></p> <p>Figura 2 - Comando \u201cjuju status\u201d no terminal.</p> <p></p> <p>Figura 3 - Dashboard do MAAS com as m\u00e1quinas.</p> <p></p> <p>Figura 4 - Aba Compute Overview no OpenStack.</p> <p></p> <p>Figura 5 - Aba Compute Instances no OpenStack.</p> <p></p> <p>Figura 6 - Aba Network Topoplogy no OpenStack.</p>"},{"location":"roteiros/roteiro3/main/#passo-3-imagens","title":"Passo 3: Imagens","text":"<ul> <li> <p>Instalando o cliente do Openstack no main via snap: <pre><code>sudo snap install openstackclients\n</code></pre></p> </li> <li> <p>Carregando as credenciais em openrc: <pre><code>source ~/openstack-bundles/stable/openstack-base/openrc\n</code></pre></p> </li> <li> <p>Verificando os servi\u00e7os dispon\u00edveis no Openstack: <pre><code>openstack service list\n</code></pre></p> </li> <li> <p>Fazendo ajustes na rede: <pre><code>juju config neutron-api enable-ml2-dns=\"true\"\njuju config neutron-api-plugin-ovn dns-servers=\"172.20.129.131\"\n</code></pre></p> </li> <li> <p>Procurando e importando a imagem do Ubuntu Jammy para o Glance: <pre><code>curl http://cloud-images.ubuntu.com/jammy/current/jammy-server-cloudimg-\namd64.img \\\n    --output ~/cloud-images/jammy-amd64.img\n\nopenstack image create --public --container-format bare \\\n    --disk-format qcow2 --file ~/cloud-images/jammy-amd64.img \\\n    jammy-amd64\n</code></pre></p> </li> </ul> <p>N\u00e3o esquecer!</p> <p>Fazer o clone do reposit\u00f3rio <code>openstack-bundles</code> caso ainda n\u00e3o tenha feito. <pre><code>git clone https://github.com/openstack-charmers/openstack-bundles\n</code></pre></p>"},{"location":"roteiros/roteiro3/main/#passo-4-rede-externa","title":"Passo 4: Rede Externa","text":"<p>Configurando uma rede externa para conectar as VMs \u00e0 rede f\u00edsica, usando uma faixa de aloca\u00e7\u00e3o entre 172.16.7.0 e 172.16.8.255:</p> <pre><code>source ~/openstack-bundles/stable/openstack-base/openrc\n\nopenstack network create --external \\\n    --provider-network-type flat --provider-physical-network physnet1 \\\n    ext_net\n\nopenstack subnet create --network ext_net --no-dhcp \\\n    --gateway 172.16.0.1 --subnet-range 172.16.0.0/20 \\\n    --allocation-pool start=172.16.7.0,end=172.16.8.255 \\\n    ext_subnet\n</code></pre>"},{"location":"roteiros/roteiro3/main/#passo-5-rede-interna-e-roteador","title":"Passo 5: Rede Interna e Roteador","text":"<p>Configurando uma rede interna para conectar as VMs \u00e0 rede externa, usando a subnet 192.169.0.0/24 e sem DNS:</p> <pre><code>openstack network create int_net\n\nopenstack subnet create --network int_net \\\n   --gateway 192.169.0.1 --subnet-range 192.169.0.0/24 \\\n   --allocation-pool start=192.169.0.10,end=192.169.0.200 \\\n   int_subnet\n</code></pre> <p>Configurando o roteador:</p> <pre><code>openstack router create provider-router\nopenstack router set --external-gateway ext_net provider-router\nopenstack router add subnet provider-router int_subnet\n</code></pre>"},{"location":"roteiros/roteiro3/main/#passo-6-flavors","title":"Passo 6: Flavors","text":"<ul> <li>Criando os flavors (instance type) - SEM ephemeral disk para as VMs:</li> </ul> Flavor Name vCPUs RAM (GB) Disk <code>m1.tiny</code> 1 1 20 <code>m1.small</code> 1 2 20 <code>m1.medium</code> 2 4 20 <code>m1.large</code> 4 8 20 <p>Tabela 1 - Flavors criados e suas respectivas configura\u00e7\u00f5es. </p> <p>Comandos: <pre><code>openstack flavor create --ram 1000 --vcpus 1 --disk 20 m1.tiny\nopenstack flavor create --ram 2000 --vcpus 1 --disk 20 m1.small\nopenstack flavor create --ram 4000 --vcpus 2 --disk 20 m1.medium\nopenstack flavor create --ram 8000 --vcpus 4 --disk 20 m1.large\n</code></pre></p>"},{"location":"roteiros/roteiro3/main/#passo-7-conexao","title":"Passo 7: Conex\u00e3o","text":"<p>O key-pair j\u00e1 existe e \u00e9 importado:</p> <pre><code>openstack keypair create --public-key ~/.ssh/id_rsa.pub open_key\n</code></pre> <ul> <li>Via o dashboard Horizon, como administrador, adicionando a libera\u00e7\u00e3o do SSH e ALL ICMP no security group default:</li> </ul> <pre><code>for i in $(openstack security group list | awk '/default/{ print $2 }'); do\n   openstack security group rule create $i --protocol icmp --remote-ip \n0.0.0.0/0;    \n   openstack security group rule create $i --protocol tcp --remote-ip \n0.0.0.0/0 --dst-port 22; \ndone\n</code></pre>"},{"location":"roteiros/roteiro3/main/#passo-8-instancia","title":"Passo 8: Inst\u00e2ncia","text":"<ul> <li> <p>Disparando uma inst\u00e2ncia m1.tiny com o nome client e sem Novo Volume: <pre><code>openstack server create --image jammy-amd64 --flavor m1.tiny \\\n   --key-name open_key --network int_net \\\n   client\n</code></pre></p> </li> <li> <p>Alocando um floating IP para a inst\u00e2ncia: <pre><code>FLOATING_IP=$(openstack floating ip create -f value -c floating_ip_address ext_net)\n\nopenstack server add floating ip client $FLOATING_IP\n</code></pre></p> </li> <li> <p>Testando a conex\u00e3o SSH: <pre><code>ssh ubuntu@$FLOATING_IP\n</code></pre></p> </li> </ul> Tarefa-2 <p>De um print das Telas abaixo:</p> <pre><code>1. Do Dashboard do MAAS com as m\u00e1quinas.\n2. Da aba compute overview no OpenStack.\n3. Da aba compute instances no OpenStack.\n4. Da aba network topology no OpenStack.\n</code></pre> <p>Enumere as diferencas encontradas entre os prints das telas na Tarefa 1 e na Tarefa 2.</p> <p>Explique como cada recurso foi criado.</p> <p></p> <p>Figura 7 - Dashboard do MAAS com as m\u00e1quinas.</p> <p></p> <p>Figura 8 - Aba Compute Overview no OpenStack.</p> <p></p> <p>Figura 9 - Aba Compute Instances no OpenStack.</p> <p></p> <p>Figura 10 - Aba Network Topoplogy no OpenStack.</p> <p>Enumere as diferencas encontradas entre os prints das telas na Tarefa 1 e na Tarefa 2.</p> <ul> <li>Compute overview: percebe-se que o n\u00famero de Inst\u00e2ncias, VCPUs, Floating IPs, security groups e Routers atualizou para 1, pois eles foram criados. Al\u00e9m disso, a mem\u00f3ria RAM agora est\u00e1 em 1GB, temos 6 rules dos security groups e a networks e a port atualizaram os valores, pois agora estamos utilizando inst\u00e2ncias; </li> <li>Compute instances: criada a inst\u00e2ncia \u201ccliente\u201d; </li> <li>Network topology: tem network, uma vez que foi criada a subnet e o roteador.</li> </ul> <p>Explique como cada recurso foi criado.</p> <p>Ap\u00f3s importar as chaves de valida\u00e7\u00e3o e imagem, e configurado a rede externa: </p> <ul> <li> <p>Rede interna e roteador: usar uma s\u00e9rie de comandos para criar rede interna, subrede e roteador, colocando os devidos valores. <pre><code>openstack network create int_net \nopenstack subnet create --network int_net --gateway 192.168.0.1 --subnet-range 192.168.0.0/24 --allocation-pool start=192.168.0.10,end=192.168.0.200 int_subnet \nopenstack router create provider-router \nopenstack router set --external-gateway ext_net provider-router \nopenstack router add subnet provider-router int_subnet\n</code></pre></p> </li> <li> <p>Security Groups Rules: usar um comando  <pre><code>openstack security group rule create\n</code></pre></p> </li> <li> <p>Inst\u00e2ncia: usar o comando a seguir passando a devida imagem, chave de valida\u00e7\u00e3o e rede.  <pre><code>openstack server create --image jammy-amd64 --flavor m1.small --key-name mykey --network int_net client\n</code></pre></p> </li> <li> <p>Endere\u00e7o de IP Flutuante: comandos abaixo, passando o nome do servidor criado anteriormente. <pre><code>FLOATING_IP=$(openstack floating ip create -f value -c floating_ip_address ext_net) openstack server add floating ip client $FLOATING_IP\n</code></pre></p> </li> </ul>"},{"location":"roteiros/roteiro3/main/#escalando-os-nos","title":"Escalando os n\u00f3s","text":"<p>No OpenStack, escalar os n\u00f3s de configura\u00e7\u00e3o \u00e9 essencial para melhorar diversos aspectos dos servi\u00e7os em um ambiente de nuvem. </p> <p>Alguns benef\u00edcios da escala dos n\u00f3s de configura\u00e7\u00e3o:</p> <ul> <li>Aumento de capacidade de processamento;</li> <li>Alta disponibilidade e toler\u00e2ncia a falhas;</li> <li>Melhoria de desempenho e lat\u00eancia reduzida;</li> <li>Escalabilidade horizontal.</li> </ul> Info <p>Para mais detalhes sobre o escalonamento de n\u00f3s no OpenStack, visitar o site da disciplina: escalonando os n\u00f3s</p> <p>Adicionando o n\u00f3 reserva ao openstack no cluster como n\u00f3 de computing e block storage.</p> <ul> <li> <p>Fazer o release da m\u00e1quina que est\u00e1 ALLOCATED no Dashboard do MaaS.</p> </li> <li> <p>Instalando o hypervisor, realizando o deploy na m\u00e1quina: <pre><code>juju add-unit nova-compute\n</code></pre></p> </li> <li> <p>Ao anotar o n\u00famero da m\u00e1quina adicionada no status, \u00e9 instalado o block storage: <pre><code>juju add-unit --to &lt;machine-id&gt; ceph-osd\n</code></pre></p> </li> </ul> Tarefa-3 <p>Fa\u00e7a um desenho de como \u00e9 a sua arquitetura de rede, desde a sua conex\u00e3o com o Insper at\u00e9 a inst\u00e2ncia alocada.</p> <p></p> <p>Figura 11 - Desenho da arquitetura de rede, da conex\u00e3o com o Insper at\u00e9 a inst\u00e2ncia alocada.</p>"},{"location":"roteiros/roteiro3/main/#app-uso-da-infraestrutura","title":"App - Uso da infraestrutura","text":"<p>Levantar 4 inst\u00e2ncias em m\u00e1quinas virtuais do OpenStack: 2 inst\u00e2ncias com a API do projeto, 1 inst\u00e2ncia com banco de dados e 1 inst\u00e2ncia com LoadBalancer (Nginx). Configurando-as como indicado a seguir:</p> <p></p> <p>Figura 12 - Topologia a ser configurada. Fonte: instru\u00e7\u00f5es da disciplina.</p> Tarefa-4 <ol> <li>Escreva um relat\u00f3rio dos passos utilizados. </li> <li>Anexe fotos e/ou diagramas contendo: arquitetura de rede da sua infraestrutura dentro do Dashboard do Openstack.</li> <li>Lista de VMs utilizadas com nome e IPs alocados </li> <li>Print do Dashboard do Wordpress conectado via m\u00e1quina Nginx/LB. </li> <li>4 Prints, cada um demonstrando em qual server  (m\u00e1quina f\u00edsica) cada instancia foi alocado pelo OpenStack.</li> </ol> <p>O relat\u00f3rio est\u00e1 presente na aba Relat\u00f3rio - Tarefa 4.</p>"},{"location":"roteiros/roteiro3/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Este roteiro apresentou, de forma pr\u00e1tica e detalhada, o processo de implanta\u00e7\u00e3o de uma nuvem privada utilizando o OpenStack em conjunto com ferramentas como MAAS, Juju e charms espec\u00edficos. </p> <p>Foram abordadas todas as etapas necess\u00e1rias para configurar a infraestrutura, desde a cria\u00e7\u00e3o do controller at\u00e9 a implanta\u00e7\u00e3o dos principais servi\u00e7os OpenStack \u2014 incluindo redes (Neutron com SDN/OVN), armazenamento (Ceph e Cinder), autentica\u00e7\u00e3o (Keystone), dashboard (Horizon), imagens (Glance), computa\u00e7\u00e3o (Nova) e banco de dados (MySQL). Al\u00e9m disso, destacou-se a import\u00e2ncia do Vault na gest\u00e3o de certificados e seguran\u00e7a. </p> <p>Ao longo do roteiro, tamb\u00e9m foram apresentadas atualiza\u00e7\u00f5es dos comandos usados, refletindo vers\u00f5es mais recentes dos componentes. O conte\u00fado permite n\u00e3o apenas a compreens\u00e3o dos conceitos fundamentais de nuvem privada, mas tamb\u00e9m oferece uma vis\u00e3o aplicada sobre redes virtuais baseadas em SDN.</p>"},{"location":"roteiros/roteiro3/relatorio/","title":"Relat\u00f3rio","text":""},{"location":"roteiros/roteiro3/relatorio/#uso-da-infraestrutura","title":"Uso da Infraestrutura","text":"<p>Com o objetivo de levantar uma aplica\u00e7\u00e3o com Nginx, WordPress e MySQL, foram realizados uma s\u00e9rie de passos e comandos que ser\u00e3o explicados ao longo do relat\u00f3rio. </p>"},{"location":"roteiros/roteiro3/relatorio/#instancias","title":"Inst\u00e2ncias","text":"<p>Primeiramente, entrou-se no Dashboard do Openstack para criar as 4 inst\u00e2ncias necess\u00e1rias na aba \"Compute\" --&gt; \"Instances\" e para configurar as inst\u00e2ncias selecionar \"Launch  Instance\". Para a configura\u00e7\u00e3o, \u00e9 necess\u00e1rio inserir alguns dados para cada uma: </p> <ul> <li>Nome da inst\u00e2ncia (aba Details) </li> <li>Selecionar source Image e alocar a imagem \"jammy-amd64\" (aba Source) </li> <li>Alocar o flavor m1.tiny (aba Flavor) </li> <li>Alocar a rede interna int_net (aba Network) </li> <li>Apenas para a inst\u00e2ncia nginx: tamb\u00e9m \u00e9 preciso alocar a rede externa ext_net </li> </ul>"},{"location":"roteiros/roteiro3/relatorio/#mysql","title":"MySQL","text":"<p>Ap\u00f3s criar a inst\u00e2ncia onde o servidor mysql ir\u00e1 rodar, ela foi acessada via ssh, e para isso foi adicionado um IP Flutuante. Ap\u00f3s acess\u00e1-la, foi instalado o mysql (mysql server), via apt e, feito isso, os arquivos de configura\u00e7\u00e3o do mysql foram alterados para que o servidor sql fosse acess\u00edvel de qualquer ponto da rede. Ap\u00f3s realizada as altera\u00e7\u00f5es, o servi\u00e7o foi reiniciado usando o comando do systemcl. Finalizando ap\u00f3s confirmar que o servidor estava acess\u00edvel externamente, foi adicionado um novo banco de dados chamado \u201cWordPress\u201d onde um novo usu\u00e1rio \u201ccloud\u201d foi dado permiss\u00e3o para realizar qualquer opera\u00e7\u00e3o nessa data-base atrav\u00e9s de qualquer host (\u201c%\u201d), terminando assim as configura\u00e7\u00f5es do MySQL e removendo o IP flutuante da inst\u00e2ncia, isolando ele \u00e0 rede interna. </p>"},{"location":"roteiros/roteiro3/relatorio/#nginx","title":"Nginx","text":"<p>Depois de criar a inst\u00e2ncia onde o servidor nginx ir\u00e1 rodar, ela foi acessada via ssh, e como neste caso a inst\u00e2ncia possui um IP externo, n\u00e3o foi necess\u00e1rio adicionar um IP flutuante para acessar a inst\u00e2ncia. Foi instalado o nginx via apt e ap\u00f3s confirmar que o servi\u00e7o estava funcionado e acess\u00edvel remotamente foi adicionado na configura\u00e7\u00e3o padr\u00e3o de sites o m\u00f3dulo \u201cUpstream\" e foi aplicada a regra para redirecionar qualquer chamada para os servidores \"Apache Web\u201d das instancias \u201cWordPress\u201d.</p>"},{"location":"roteiros/roteiro3/relatorio/#wordpress","title":"WordPress","text":"<p>Para a instala\u00e7\u00e3o e configura\u00e7\u00e3o das inst\u00e2ncias do \u201cWordPress\u201d foi adicionado um IP Flutuante em cada inst\u00e2ncia para conectar via ssh e ap\u00f3s o acesso foram seguidos os passos do tutorial no link: https://ubuntu.com/tutorials/install-and-configure-wordpress#1-overview, instalando as depend\u00eancias e o \u201cWordpress\u201d, configurando o apache e, por fim, configurando o worpress para conectar \u00e0 base de dados do mysql remoto em vez de local. Conclu\u00edda a instala\u00e7\u00e3o e configura\u00e7\u00e3o do \u201cWordpress\u201d em cada inst\u00e2ncia, os IPs Flutuantes foram removidos.</p>"},{"location":"roteiros/roteiro3/relatorio/#rede-e-maquinas-funcionando","title":"Rede e M\u00e1quinas funcionando","text":"<p>Figura 1 - Desenho da arquitetura de rede, da conex\u00e3o com o Insper at\u00e9 as inst\u00e2ncias alocadas.</p> <p></p> <p>Figura 2 - Arquitetura de rede da infraestrutura no Dashboard do Openstack.</p> <p></p> <p>Figura 3 - Print do Dashboard do Wordpress conectado via m\u00e1quina Nginx/LB. </p> <p></p> <p>Figura 4 - Print dos NATs existentes, mostrando o NAT do Nginx.</p> <p></p> <p>Figura 5 - Print mostrando qual m\u00e1quina a inst\u00e2ncia mysql foi alocada pelo OpenStack.</p> <p></p> <p>Figura 6 - Print mostrando qual m\u00e1quina a inst\u00e2ncia wordpress-1 foi alocada pelo OpenStack.</p> <p></p> <p>Figura 7 - Print mostrando qual m\u00e1quina a inst\u00e2ncia wordpress-2 foi alocada pelo OpenStack.</p> <p></p> <p>Figura 8 - Print mostrando qual m\u00e1quina a inst\u00e2ncia nginx foi alocada pelo OpenStack.</p> <p>Para uma maior facilidade de visualiza\u00e7\u00e3o das VMs, com seus nomes, m\u00e1quinas e IPs, consultar a Tabela 1 a seguir: </p> Nome M\u00e1quina IP alocado <code>MySQL</code> mysql Server 5 192.169.0.188 <code>WordPress</code> wordpress-1 Server 5 192.169.0.93 - 172.16.7.26 <code>WordPress</code> wordpress-2 Server 2 192.169.0.79 - 172.16.8.36 <code>Nginx</code> ngynx Server 5 192.169.0.108 - 172.16.8.133 <p>Tabela 1 - VMs utilizadas, com seus nomes e IPs. </p>"},{"location":"roteiros/roteiro4/main/","title":"Roteiro","text":""},{"location":"roteiros/roteiro4/main/#objetivo","title":"Objetivo","text":"<p>O objetivo principal desse roteiro \u00e9:</p> <ul> <li>entender os conceitos b\u00e1sicos de Infraestrutura como C\u00f3digo</li> <li>entender os conceitos b\u00e1sicos sobre SLA e DR</li> </ul>"},{"location":"roteiros/roteiro4/main/#roteiro","title":"Roteiro","text":"<p>Para visualizar o arquivo PDF feito e entregue, consultar o link a seguir: Roteiro 4 - PDF.</p>"},{"location":"roteiros/roteiro4/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Infraestrutura como C\u00f3digo (IaC) \u00e9 uma abordagem que automatiza o provisionamento e gerenciamento da infraestrutura por meio de arquivos de configura\u00e7\u00e3o, substituindo processos manuais. Isso garante ambientes padronizados, facilita a manuten\u00e7\u00e3o e evita altera\u00e7\u00f5es n\u00e3o documentadas.</p> <p>O Terraform, ferramenta da HashiCorp, \u00e9 amplamente utilizado em IaC por permitir a defini\u00e7\u00e3o declarativa da infraestrutura, al\u00e9m de suportar m\u00faltiplos provedores de nuvem e facilitar o gerenciamento do ciclo de vida dos recursos com comandos como init, plan e apply.</p> <p>J\u00e1 o OpenStack oferece uma solu\u00e7\u00e3o de IaaS flex\u00edvel, permitindo gerenciar ambientes de nuvem privados e p\u00fablicos. Com componentes como Domains, Projects, Users e Roles, organizados pelo Keystone (sistema de IAM), ele proporciona controle de acesso e segmenta\u00e7\u00e3o de recursos em ambientes multiusu\u00e1rio.</p>"},{"location":"roteiros/roteiro4/main/#infra","title":"Infra","text":"<p>S\u00e3o criados um dom\u00ednio, dois projetos e dois usu\u00e1rios \"Aluno\", um em cada projeto, no OpenStack via Horizon Dashboard.</p>"},{"location":"roteiros/roteiro4/main/#criar-um-unico-domain","title":"Criar um \u00fanico Domain","text":"<ul> <li>Identity -&gt; Domains -&gt; Create Domain</li> <li>nome para o dom\u00ednio: AlunosDomain</li> <li>clicar em Create Domain para finalizar a cria\u00e7\u00e3o</li> <li>definir o Domain criado com o novo Contexto de Uso</li> </ul>"},{"location":"roteiros/roteiro4/main/#criar-um-projeto-para-cada-aluno","title":"Criar um Projeto para cada aluno","text":"<ul> <li>Identity -&gt; Projects -&gt; Create Project</li> <li>nome para o projeto KitU_nome_aluno e configurar qualquer quota que desejar</li> <li>clicar em Create Project para concluir</li> </ul>"},{"location":"roteiros/roteiro4/main/#criar-um-usuario-para-cada-aluno","title":"Criar um Usu\u00e1rio para cada aluno","text":"<ul> <li>Identity -&gt; Users -&gt; Create User</li> <li>fornecer o nome do usu\u00e1rio, e-mail, descri\u00e7\u00e3o, e uma senha inicial</li> <li>selecionar o dom\u00ednio criado e o projeto do aluno</li> <li>atribuir os pap\u00e9is administrativos</li> <li>clicar em Create User para finalizar</li> </ul>"},{"location":"roteiros/roteiro4/main/#app","title":"App","text":""},{"location":"roteiros/roteiro4/main/#criando-a-infraestrutura-utilizando-iac","title":"Criando a Infraestrutura utilizando IaC","text":"<p>O Terraform conta com arquivos .tf, que definem a infraestrutura. Cada aluno entra no MAIN pela sua m\u00e1quina e cria a estrutura abaixo.</p> Estrutura de pastas<pre><code>\ud83d\udcc1 KitU_Aluno/  \n\u251c\u2500\u2500 \ud83d\udcc1 terraform/\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 instance1.tf\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 instance2.tf\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 network.tf\n\u2502   \u251c\u2500\u2500 \ud83d\udcc4 provider.tf\n\u2502   \u2514\u2500\u2500 \ud83d\udcc4 router.tf\n\u2514\u2500\u2500 \ud83d\udcc4 KitU_Aluno-openrc.sh\n</code></pre>"},{"location":"roteiros/roteiro4/main/#credenciais-do-seu-usuario","title":"Credenciais do seu usu\u00e1rio","text":"<ul> <li>entrar no dashboard com o login do usu\u00e1rio</li> <li>Project -&gt; API Access</li> <li>fazer o download do openstack rc file do usu\u00e1rio</li> <li>copiar o conte\u00fado para <code>KitU_Aluno-openrc.sh</code></li> <li>dar a permiss\u00e3o de execu\u00e7\u00e3o para o arquivo     <pre><code>chmod +x KitU_Aluno-openrc.sh\n</code></pre></li> <li> <p>carregando as vari\u00e1veis de ambiente</p> extra <p>O comando de carregar as vari\u00e1veis de ambiente no roteiro anterior foi: <pre><code>source ~/openstack-bundles/stable/openstack-base/openrc\n</code></pre></p> <pre><code>source KitU_Aluno-openrc.sh\n</code></pre> </li> </ul>"},{"location":"roteiros/roteiro4/main/#implementacao-da-infraestrutura","title":"Implementa\u00e7\u00e3o da infraestrutura","text":"<ul> <li>iniciar o terraform     <pre><code>terraform init\n</code></pre></li> <li>criar um plano de execu\u00e7\u00e3o     <pre><code>terraform plan\n</code></pre></li> <li>mudan\u00e7as aplicadas para alcan\u00e7ar o estado desejado da sua configura\u00e7\u00e3o     <pre><code>terraform apply\n</code></pre></li> </ul> Check-point: Admin <p>Figura 1 - Aba Identity projects no OpenStack.</p> <p></p> <p>Figura 2 - Aba Identity users no OpenStack.</p> Check-point: Giovana <p>De um print das Telas abaixo:</p> <pre><code>1. Da aba Identy projects no OpenStack.\n2. Da aba Identy users no OpenStack.\n3. Da aba compute overview no OpenStack.\n4. Da aba compute instances no OpenStack.\n5. Da aba network topology no OpenStack.\n</code></pre> <p></p> <p>Figura 3 - Aba Identity projects no OpenStack \u2013 Giovana.</p> <p></p> <p>Figura 4 - Aba Identity users no OpenStack \u2013 Giovana.</p> <p></p> <p>Figura 5 - Aba Compute Overview no OpenStack \u2013 Giovana.</p> <p></p> <p>Figura 6 - Aba Compute Instances no OpenStack \u2013 Giovana.</p> <p></p> <p>Figura 7 - Aba Network Topology no OpenStack \u2013 Giovana.</p> <p></p> <p>Figura 8 - Print do terminal com terraform apply completo \u2013 Giovana. </p> Check-point: Lucas <p>De um print das Telas abaixo:</p> <pre><code>1. Da aba Identy projects no OpenStack.\n2. Da aba Identy users no OpenStack.\n3. Da aba compute overview no OpenStack.\n4. Da aba compute instances no OpenStack.\n5. Da aba network topology no OpenStack.\n</code></pre> <p></p> <p>Figura 9 - Aba Identity projects no OpenStack \u2013 Lucas.</p> <p></p> <p>Figura 10 - Aba Identity users no OpenStack \u2013 Lucas.</p> <p></p> <p>Figura 11 - Aba Compute Overview no OpenStack \u2013 Lucas.</p> <p></p> <p>Figura 12 - Aba Compute Instances no OpenStack \u2013 Lucas.</p> <p></p> <p>Figura 13 - Aba Network Topology no OpenStack \u2013 Lucas.</p> <p></p> <p>Figura 14 - Print do terminal com terraform apply completo \u2013 Lucas.</p>"},{"location":"roteiros/roteiro4/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Neste roteiro, foi poss\u00edvel compreender e aplicar conceitos fundamentais de Infraestrutura como C\u00f3digo (IaC) e gest\u00e3o de identidade e acesso em nuvens privadas. </p> <p>Ao interagir com o OpenStack por meio do Horizon Dashboard, o entendimento sobre a estrutura organizacional e os mecanismos de controle de acesso dessa plataforma foi consolidado.</p> <p>A integra\u00e7\u00e3o do Terraform com o OpenStack demonstrou a import\u00e2ncia de configurar corretamente as credenciais, recursos de rede e inst\u00e2ncias de m\u00e1quina virtual.</p> <p>Por fim, o roteiro introduziu conceitos importantes relacionados a SLA (Acordo de N\u00edvel de Servi\u00e7o) e DR (Recupera\u00e7\u00e3o de Desastres).</p>"},{"location":"roteiros/roteiro4/questoes/","title":"Criando um plano de Disaster Recovery e SLA","text":"<p>Voc\u00ea \u00e9 o CTO (Chief Technology Officer) de uma grande empresa com sede em v\u00e1rias capitais no Brasil e precisa implantar um sistema cr\u00edtico, de baixo custo e com dados sigilosos para a \u00e1rea operacional.</p> <p>A. Voc\u00ea escolheria Public Cloud ou Private Cloud?</p> <p>Para as tarefas de processamento, seria beneficial escolher uma Public Cloud, devido \u00e0 alta disponibilidade e escalabilidade. E para as tarefas que requerem maior seguran\u00e7a seria melhor uma Private Cloud, proporcionando um  maior controle da seguran\u00e7a de dados sigilosos e uma baixa lat\u00eancia para trabalhos. Logo, uma boa escolha seria fazer uma Nuvem H\u00edbrida, possuindo boa seguran\u00e7a e flexibilidade, mas vale-se mencionar que \u00e9 complexo integrar e gerenciar os ambientes das duas nuvens eficientemente e que os funcion\u00e1rios devem possuir a habilidade de lidar com os dois ambientes. </p> <p>B. Agora explique para ao RH por que voc\u00ea precisa de um time de DevOps.</p> <p>Um time de DevOps \u00e9 necess\u00e1rio, uma vez que, al\u00e9m de fornecer uma  grande escalabilidade e efici\u00eancia, ele seria respons\u00e1vel por atualiza\u00e7\u00f5es e melhorias peri\u00f3dicas, pela automa\u00e7\u00e3o de processos e pelo monitoramento, rapidamente identificando problemas e implementando solu\u00e7\u00f5es.</p> <p>C. Considerando o mesmo sistema cr\u00edtico, agora sua equipe dever\u00e1 planejar e implementar um ambiente resiliente e capaz de mitigar  poss\u00edveis interrup\u00e7\u00f5es/indisponibilidades. Para isso, identifiquem quais s\u00e3o as principais amea\u00e7as que podem colocar sua infraestrutura em risco, e descreva as principais a\u00e7\u00f5es que possibilitem o restabelecimento de todas as aplica\u00e7\u00f5es de forma r\u00e1pida e organizada caso algum evento cause uma interrup\u00e7\u00e3o ou incidente de seguran\u00e7a. Para isso monte um plano de DR e HA que considere entre as a\u00e7\u00f5es:</p> <ul> <li>Mapeamento das principais amea\u00e7as que podem colocar em riscos o seu ambiente.</li> <li>Elenque e priorize as a\u00e7\u00f5es para a recupera\u00e7\u00e3o de seu ambiente em uma poss\u00edvel interrup\u00e7\u00e3o/desastre.</li> <li>Como sua equipe ir\u00e1 tratar a pol\u00edtica de backup?</li> <li>Considerando poss\u00edveis instabilidades e problemas, descreva como alta disponibilidade ser\u00e1 implementada em sua infraestrutura.</li> </ul> <p>Amea\u00e7as:</p> <ul> <li>Ataques hackers, falhas de hardware, erro humano e instabilidade de rede. </li> </ul> <p>Recupera\u00e7\u00e3o de ambiente:</p> <ul> <li>Backup automatizado e servidores redundantes. </li> </ul> <p>Pol\u00edtica de backup:</p> <ul> <li>Frequente, criptografia e armazenar em mais de um servidor. </li> </ul> <p>Alta disponibilidade:</p> <ul> <li>Load balancer e estrat\u00e9gia de multi-cloud.</li> </ul>"}]}